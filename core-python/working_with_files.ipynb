{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILES AND DIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas\n",
    "\n",
    "def list_dir(fld):\n",
    "    for fn in os.listdir(fld):\n",
    "        print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/10 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/5 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.500000000000004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22/80  * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 5/100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi\n",
      "customer-orders.csv\n",
      "fakefriends-header.csv\n",
      "sample.txt\n",
      "book.txt\n",
      "london_weather.csv\n",
      "fakefriends.csv\n",
      "output\n",
      "1800.csv\n"
     ]
    }
   ],
   "source": [
    "list_dir('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.txt\n",
      "book.txt\n",
      "-----------------------------\n",
      "fakefriends-header.csv\n",
      "fakefriends.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def end_with(fld, search):\n",
    "    for fn in os.listdir(fld):\n",
    "        if fn.endswith(search):\n",
    "            print(fn)\n",
    "\n",
    "\n",
    "def starts_with(fld, search):\n",
    "    for fn in os.listdir(fld):\n",
    "        if fn.startswith(search):\n",
    "            print(fn)\n",
    "\n",
    "\n",
    "end_with('../data/', '.txt')\n",
    "print('-----------------------------')\n",
    "starts_with('../data/', 'fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def match(fld, search):\n",
    "    for fn in os.listdir(fld):\n",
    "        if fnmatch.fnmatch(fn, search):\n",
    "            print(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer-orders.csv\n",
      "fakefriends-header.csv\n",
      "london_weather.csv\n",
      "fakefriends.csv\n",
      "1800.csv\n"
     ]
    }
   ],
   "source": [
    "match('../data/', '*csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "def match(fld, search):\n",
    "    for fn in os.listdir(fld):\n",
    "        if fnmatch.fnmatch(fn, search):\n",
    "            print(fn)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_date(timestamp):\n",
    "    return datetime.utcfromtimestamp(timestamp).strftime('%d %m %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_attrs(fld):\n",
    "    with os.scandir(fld) as dir:\n",
    "        for f in dir:\n",
    "            if f.is_file():\n",
    "                inf = f.stat()\n",
    "                print(f'Modified {get_date(inf.st_mtime)} {f.name}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def traverse(fld):\n",
    "    for fldpath, dirs, fls in os.walk(fld):\n",
    "        print(f'Folder: {fldpath}')\n",
    "        \n",
    "        for f in fls:\n",
    "            print(f'Files: {f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def remove_file(f):\n",
    "    if os.path.isfile(f):\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(f'Error: {f} : {e.strerror}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_file('test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARCHIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_zip = [\n",
    "    '../data/customer-orders.csv',\n",
    "    '../data/fakefriends-header.csv', \n",
    "    '../data/sample.txt'\n",
    "]\n",
    "\n",
    "\n",
    "def create_zip(zipf, files, opt):\n",
    "    with zipfile.ZipFile(zipf, opt, allowZip64=True) as archive:\n",
    "        for f in files:\n",
    "            archive.write(f)\n",
    "\n",
    "create_zip('./data.zip', to_zip, 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = [\n",
    "    '../data/book.txt',\n",
    "    '../data/london_weather.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_zip(zipf, files, opt):\n",
    "    with zipfile.ZipFile(zipf, opt, allowZip64=True) as archive:\n",
    "        for f in files:\n",
    "            lst = archive.namelist()\n",
    "            if not f in lst:\n",
    "                archive.write(f)\n",
    "\n",
    "            else:\n",
    "                print('aready exist')\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_zip('./data.zip', to_add, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zip(zipf):\n",
    "\n",
    "    with zipfile.ZipFile(zipf, 'r') as archive:\n",
    "        lst = archive.namelist()\n",
    "        for l in lst:\n",
    "            zfinf = archive.getinfo(l)\n",
    "            print(f'{l} => {zfinf.file_size} bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/customer-orders.csv => 146855 bytes\n",
      "../data/fakefriends-header.csv => 8779 bytes\n",
      "../data/sample.txt => 42 bytes\n",
      "../data/book.txt => 264875 bytes\n",
      "../data/london_weather.csv => 814426 bytes\n"
     ]
    }
   ],
   "source": [
    "read_zip('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def extract_file(zipf, fn, path):\n",
    "    with zipfile.ZipFile(zipf, 'r') as archive:\n",
    "        archive.extract(fn, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all(zipf, path):\n",
    "    with zipfile.ZipFile(zipf, 'r') as archive:\n",
    "        archive.extractall(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_file('./data.zip', '../data/book.txt', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_all('./data.zip', './data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILE FORMATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(fn):\n",
    "    with open(fn) as f:\n",
    "        print(f.read())\n",
    "\n",
    "def read_txt_by_line(fn):\n",
    "    with open(fn) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            print(line, end='')\n",
    "            line = f.readline()\n",
    "\n",
    "def write_new_txt(fn, str):\n",
    "    with open(fn, 'w', encoding='utf-8') as f:\n",
    "        f.write(str)\n",
    "\n",
    "def append_line_txt(fn, str):\n",
    "    with open(fn, 'a', encoding='utf-8') as f:\n",
    "        f.write('\\n')\n",
    "        f.write(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "read_txt('../data/sample.txt')\n",
    "#write_new_txt('../data/sample.txt', 'test')\n",
    "#append_line_txt('../data/sample.txt', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv(fn, delimiter):\n",
    "    with open(fn) as csv_file:\n",
    "        cnt = -1\n",
    "        rows = csv.reader(csv_file, delimiter=delimiter)\n",
    "        for r in rows:\n",
    "            if cnt == -1 :\n",
    "                print(f'{ \" | \".join(r)}')\n",
    "            else:\n",
    "                print(f'{r[0]} | {r[1]} | {r[2]} | {r[3]}')\n",
    "            cnt += 1\n",
    "        print(f'{cnt} lines')\n",
    "\n",
    "\n",
    "#read_csv('../data/1800.csv', ',')\n",
    "\n",
    "\n",
    "def write_csv(fn, header, row):\n",
    "    with open(fn, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(header)\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_xml_et(file):\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    #print('Books for: ', root.attrib['id'])\n",
    "    for child in root:\n",
    "        print('\\t' + child.attrib['id'], child.tag)\n",
    "        for sub in child.findall('book'):\n",
    "            print('\\t' + sub.find('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbk101 book\n",
      "\tbk102 book\n",
      "\tbk103 book\n",
      "\tbk104 book\n",
      "\tbk105 book\n",
      "\tbk106 book\n",
      "\tbk107 book\n",
      "\tbk108 book\n",
      "\tbk109 book\n",
      "\tbk110 book\n",
      "\tbk111 book\n",
      "\tbk112 book\n"
     ]
    }
   ],
   "source": [
    "parse_xml_et('../data/book_catalog.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "class Person:\n",
    "    age = 45\n",
    "    name = 'Radi'\n",
    "    kids = ['Simona', 'Kris']\n",
    "    employers = {'NEXO': 2022}\n",
    "    shoe_sizes = [47, 48]\n",
    "\n",
    "def serealize(obj):\n",
    "    pickled = pickle.dumps(obj, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'Serealized object: {pickled}')\n",
    "    return pickled\n",
    "\n",
    "\n",
    "def deserialize(obj):\n",
    "    unpickled = pickle.loads(obj)\n",
    "    print(f'Deserialized \\n{unpickled} \\n')\n",
    "    print(f'deserialized \\n{unpickled.employers}')\n",
    "    return unpickled \n",
    "\n",
    "def obj_to_file(file, obj):\n",
    "    with open(file, 'wb') as pf:\n",
    "        pickle.dump(obj, pf, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def file_to_obj(file, obj):\n",
    "    with open(file, 'rb') as pf:\n",
    "        obj = pickle.load(pf)\n",
    "        print(obj)\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Person at 0x7f0cf84813a0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Person()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serealized object: b'\\x80\\x05\\x95\\x1a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main__\\x94\\x8c\\x06Person\\x94\\x93\\x94)\\x81\\x94.'\n"
     ]
    }
   ],
   "source": [
    "pick = serealize(Person())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deserialized \n",
      "<__main__.Peson object at 0x7f0cf8497a70> \n",
      "\n",
      "deserialized \n",
      "{'NEXO': 2022}\n"
     ]
    }
   ],
   "source": [
    "unpick = deserialize(pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = obj_to_file('test.xyz', Person())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Person object at 0x7f0cf85a78f0>\n"
     ]
    }
   ],
   "source": [
    "person = file_to_obj('test.xyz', obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8450.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6500 + 6500 * 0.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
